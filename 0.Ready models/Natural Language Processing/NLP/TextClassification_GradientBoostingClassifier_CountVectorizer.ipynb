{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Text Classification using GradientBoostingClassifier and CountVectorizer"
   ],
   "metadata": {
    "id": "iws1EZcbaquY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This Code Template is for Text Classification using GradientBoostingClassifier based on the Gradient Boosting Ensemble Learning Technique along with Text Feature technique CountVectorizer from Scikit-learn in python."
   ],
   "metadata": {
    "id": "3sYA5-5xayzK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Required Packages"
   ],
   "metadata": {
    "id": "DxclZ9Jka773"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install nltk\r\n",
    "!pip install imblearn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "import numpy as np \r\n",
    "import pandas as pd \r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as se\r\n",
    "import re, string\r\n",
    "import nltk\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.corpus import stopwords, wordnet\r\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\r\n",
    "nltk.download('stopwords')\r\n",
    "nltk.download('punkt')\r\n",
    "nltk.download('averaged_perceptron_tagger')\r\n",
    "nltk.download('wordnet')\r\n",
    "from imblearn.over_sampling import RandomOverSampler\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.metrics import plot_confusion_matrix,classification_report\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\AKSHAR\n",
      "[nltk_data]     NERKAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\AKSHAR\n",
      "[nltk_data]     NERKAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\AKSHAR NERKAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\AKSHAR\n",
      "[nltk_data]     NERKAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVQ8QbNMa9SM",
    "outputId": "c17a2354-e5ca-4626-f5d9-8270beb87842"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialization"
   ],
   "metadata": {
    "id": "vcKNbYf-cFXE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filepath of CSV file"
   ],
   "metadata": {
    "id": "gMC9nA6dcFl2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#filepath\n",
    "file_path= \"\""
   ],
   "outputs": [],
   "metadata": {
    "id": "XYms4d_4cLcc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Target** variable for prediction."
   ],
   "metadata": {
    "id": "tYMsqgb2gezr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "target=''"
   ],
   "outputs": [],
   "metadata": {
    "id": "8dqaqzN4ghl9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Text column containing all the text data\n"
   ],
   "metadata": {
    "id": "thVb7na9glcy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "text=\"\""
   ],
   "outputs": [],
   "metadata": {
    "id": "FWgps0zmgpB9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Fetching"
   ],
   "metadata": {
    "id": "-wZ37AFSdTPW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pandas is an open-source, BSD-licensed library providing high-performance, easy-to-use data manipulation and data analysis tools.\n",
    "\n",
    "We will use panda's library to read the CSV file using its storage path.And we use the head function to display the initial row or entry."
   ],
   "metadata": {
    "id": "u_bvM8SadTpO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df=pd.read_csv(file_path)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "vbgp9mOggxtI",
    "outputId": "7744a9b5-cef0-4382-9c79-8e6fd931153f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preprocessing"
   ],
   "metadata": {
    "id": "7FKVbIjqj-0_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The text data might contain noise in various forms like emotions, punctuation, text in a different case etc. We apply various text preprocessing methods such as converting text to lowercase, remove text in square brackets, remove links, remove special characters and remove words containing numbers to clean the text data and make it ready to feed data to the model.\n",
    "\n",
    "We also apply lemmetization technique to the data which groups together the different canonical forms of a word so they can be analysed as a single item which ultimately improves model accuracy."
   ],
   "metadata": {
    "id": "renAqXpkj-35"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#convert to lowercase, strip and remove punctuations\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    "\n",
    " \n",
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)\n",
    "\n",
    "def textfinalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "\n",
    "def data_preprocess(df, target):\n",
    "    df = df.dropna(axis=0, how = 'any')\n",
    "    df[target] = LabelEncoder().fit_transform(df[target])    \n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {
    "id": "gy_OFA53kD_J"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df = data_preprocess(df, target)\n",
    "df[text] = df[text].apply(lambda x: textfinalpreprocess(x))\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah think go usf life around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message\n",
       "0         0  go jurong point crazy available bugis n great ...\n",
       "1         0                            ok lar joking wif u oni\n",
       "2         1  free entry wkly comp win fa cup final tkts st ...\n",
       "3         0                u dun say early hor u c already say\n",
       "4         0                nah think go usf life around though"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "4ajKAt-1v220",
    "outputId": "ca5eebe4-7f11-4b60-d3c3-3499993809bf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Selections"
   ],
   "metadata": {
    "id": "_pAHqMokjI0Q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is the process of reducing the number of input variables when developing a predictive model. Used to reduce the number of input variables to both reduce the computational cost of modelling and, in some cases, to improve the performance of the model.\n",
    "\n",
    "We will assign all the required input features to X and target/outcome to Y."
   ],
   "metadata": {
    "id": "mtsrehs6jJDK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X=df[text]\n",
    "Y=df[target]"
   ],
   "outputs": [],
   "metadata": {
    "id": "_MNVdxu6jMjD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Distribution Of Target Variable"
   ],
   "metadata": {
    "id": "RwwCPRS3Du30"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "se.countplot(Y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Category', ylabel='count'>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "dobw-AfYDy3g",
    "outputId": "d25a4d8b-5d1f-423b-ea12-5bf2d442fcfc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Splitting\n",
    "Since we are using a univariate dataset, we can directly split our data into training and testing subsets. The first subset is utilized to fit/train the model. The second subset is used for prediction. The main motive is to estimate the performance of the model on new data."
   ],
   "metadata": {
    "id": "u3iVx_6v_-De"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=123)"
   ],
   "outputs": [],
   "metadata": {
    "id": "jKoGwzU3AAkW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Transformation"
   ],
   "metadata": {
    "id": "ufHKpTiN90UC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**CountVectorizer** is a text transformation technique provided by the scikit-learn library that transforms a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text.\n",
    "\n",
    "It converts a collection of text documents to a matrix of token counts\n",
    "\n",
    "***For more information on CountVectorizer [click here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)***"
   ],
   "metadata": {
    "id": "R_PpHDfQ-BJU"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(x_train)\n",
    "\n",
    "x_train = vectorizer.transform(x_train)\n",
    "x_test  = vectorizer.transform(x_test)"
   ],
   "outputs": [],
   "metadata": {
    "id": "WU9H2MXk-b70"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Handling Target Imbalance\n",
    "The challenge of working with imbalanced datasets is that most machine learning techniques will ignore, and in turn have poor performance on, the minority class, although typically it is performance on the minority class that is most important.\n",
    "\n",
    "One approach to addressing imbalanced datasets is to oversample the minority class. The simplest approach involves duplicating examples in the minority class.We will perform overspampling using imblearn library."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "x_train,y_train = RandomOverSampler(random_state=123).fit_resample(x_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model\n",
    "\n",
    "Gradient Boosting builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions.In each stage n_classes_ regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. \n",
    "\n",
    " #### Model Tuning Parameters\n",
    "\n",
    "    1. loss : {‘deviance’, ‘exponential’}, default=’deviance’\n",
    "> The loss function to be optimized. ‘deviance’ refers to deviance (= logistic regression) for classification with probabilistic outputs. For loss ‘exponential’ gradient boosting recovers the AdaBoost algorithm.\n",
    "\n",
    "    2. learning_ratefloat, default=0.1\n",
    "> Learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators.\n",
    "\n",
    "    3. n_estimators : int, default=100\n",
    "> The number of trees in the forest.\n",
    "\n",
    "    4. criterion : {‘friedman_mse’, ‘mse’, ‘mae’}, default=’friedman_mse’\n",
    "> The function to measure the quality of a split. Supported criteria are ‘friedman_mse’ for the mean squared error with improvement score by Friedman, ‘mse’ for mean squared error, and ‘mae’ for the mean absolute error. The default value of ‘friedman_mse’ is generally the best as it can provide a better approximation in some cases.\n",
    "\n",
    "    5. max_depth : int, default=3\n",
    "> The maximum depth of the individual regression estimators. The maximum depth limits the number of nodes in the tree. Tune this parameter for best performance; the best value depends on the interaction of the input variables.\n",
    "\n",
    "    6. max_features : {‘auto’, ‘sqrt’, ‘log2’}, int or float, default=None\n",
    "> The number of features to consider when looking for the best split:  \n",
    "\n",
    "    7. random_state : int, RandomState instance or None, default=None\n",
    "> Controls both the randomness of the bootstrapping of the samples used when building trees (if <code>bootstrap=True</code>) and the sampling of the features to consider when looking for the best split at each node (if `max_features < n_features`).\n",
    "\n",
    "    8. verbose : int, default=0\n",
    "> Controls the verbosity when fitting and predicting.\n",
    "    \n",
    "    9. n_iter_no_change : int, default=None\n",
    "> <code>n_iter_no_change</code> is used to decide if early stopping will be used to terminate training when validation score is not improving. By default it is set to None to disable early stopping. If set to a number, it will set aside <code>validation_fraction</code> size of the training data as validation and terminate training when validation score is not improving in all of the previous <code>n_iter_no_change</code> numbers of iterations. The split is stratified.\n",
    "    \n",
    "    10. tol : float, default=1e-4\n",
    "> Tolerance for the early stopping. When the loss is not improving by at least tol for <code>n_iter_no_change</code> iterations (if set to a number), the training stops."
   ],
   "metadata": {
    "id": "DOhgjmbaCQwC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model=GradientBoostingClassifier()\n",
    "model.fit(x_train,y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQ1b_UYhAoB4",
    "outputId": "ead85146-b112-4297-9986-c59e33dc318c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model Accuracy\n",
    "score() method return the mean accuracy on the given test data and labels.\n",
    "\n",
    "In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted."
   ],
   "metadata": {
    "id": "GYatcCDDC2JP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(\"Accuracy score {:.2f} %\\n\".format(model.score(x_test,y_test)*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score 94.53 %\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8b5oAH7C3Ya",
    "outputId": "03064f1b-1706-403a-bd46-aa723fcd8a53"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Confusion Matrix\n",
    "A confusion matrix is utilized to understand the performance of the classification model or algorithm in machine learning for a given test set where results are known."
   ],
   "metadata": {
    "id": "yas-d-CAC9bz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "plot_confusion_matrix(model,x_test,y_test,cmap=plt.cm.Blues)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x160068cafd0>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "MXz0euBYC-95",
    "outputId": "6e7b964e-0d72-4182-b497-9c049ef6ba7c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Classification Report\n",
    "A Classification report is used to measure the quality of predictions from a classification algorithm. How many predictions are True, how many are False.\n",
    "* where:\n",
    "  - Precision:- Accuracy of positive predictions.\n",
    "  -  Recall:- Fraction of positives that were correctly identified.\n",
    "  -  f1-score:- percent of positive predictions were correct\n",
    "  -  support:- Support is the number of actual occurrences of the class in the specified dataset."
   ],
   "metadata": {
    "id": "gny6G4OsDBTT"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "print(classification_report(y_test,model.predict(x_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       962\n",
      "           1       0.75      0.90      0.82       153\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.87      0.92      0.89      1115\n",
      "weighted avg       0.95      0.95      0.95      1115\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AowdAdt4DaPh",
    "outputId": "9e53e419-38e2-4f51-8f4e-440260a854cc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creator: Akshar Nerkar , Github: [Profile](https://github.com/Akshar777)"
   ],
   "metadata": {
    "id": "R2tcbGJGDhK4"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}